# Full-RAG: Asynchronous GenAI System Design

A production-ready, asynchronous document processing system demonstrating real-world GenAI architecture patterns with microservices, background job processing, and cloud deployment.

## ğŸ¯ Project Overview

This project showcases a **scalable, asynchronous GenAI system** that processes PDF documents (resumes) and generates AI-powered analysis using OpenAI's vision API. The architecture mimics enterprise-grade AI systems with decoupled services, message queues, and containerized deployment.

### Key Learning Objectives

- **Asynchronous Architecture**: Server processes are completely detached from AI workers for non-blocking operations
- **Microservices Pattern**: Separate services for API, workers, database, and cache
- **Cloud Deployment**: Deployed as Docker containers on AWS EC2 with Elastic IP
- **Load Balancing**: Implemented load balancer for efficient scaling and high availability
- **Containerization**: Full Docker-based development and production environments

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Load Balancer â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ FastAPI â”‚ â”€â”€â”€â”€â”€â”€â”
    â”‚ Server  â”‚       â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â”‚
         â”‚            â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
    â”‚ MongoDB â”‚  â”‚ Valkeyâ”‚
    â”‚         â”‚  â”‚(Redis)â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”˜
                     â”‚
                â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                â”‚   RQ    â”‚
                â”‚ Workers â”‚
                â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                     â”‚
                â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                â”‚ OpenAI  â”‚
                â”‚   API   â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How It Works

1. **Client uploads PDF** â†’ FastAPI receives and saves to disk
2. **Job queued** â†’ Task pushed to Redis Queue (RQ) for async processing
3. **Worker picks up job** â†’ Independent worker process handles the task
4. **PDF to Images** â†’ Converts PDF pages to JPEG images
5. **AI Analysis** â†’ Sends images to OpenAI Vision API for analysis
6. **Result stored** â†’ Updates MongoDB with processing results
7. **Client polls status** â†’ Retrieves results via GET endpoint

## ğŸš€ Features

- âœ… **Async File Upload** with FastAPI
- âœ… **Background Job Processing** with Redis Queue
- âœ… **PDF to Image Conversion** using pdf2image
- âœ… **AI-Powered Analysis** with OpenAI Vision API
- âœ… **Status Tracking** with MongoDB
- âœ… **Dockerized Development** with DevContainers
- âœ… **Production Deployment** on AWS EC2
- âœ… **Load Balancing** for scalability

## ğŸ› ï¸ Tech Stack

**Backend Framework**
- FastAPI (async web framework)
- Uvicorn (ASGI server)

**Task Queue**
- Redis Queue (RQ)
- Valkey (Redis fork)

**Database**
- MongoDB (async with Motor)

**AI/ML**
- OpenAI API (Vision)
- pdf2image + Pillow

**DevOps**
- Docker & Docker Compose
- AWS EC2
- Elastic Load Balancer
- Elastic IP

## ğŸ“¦ Installation

### Local Development with DevContainers

1. **Clone the repository**
   ```bash
   git clone <repo-url>
   cd full-rag
   ```

2. **Open in DevContainer**
   - Open in VS Code
   - Reopen in Container (uses `.devcontainer/`)

3. **Set up environment variables**
   ```bash
   cp .env.example .env
   # Edit .env and add your OPENAI_API_KEY
   ```

4. **Run the application**
   ```bash
   ./run.sh
   ```

### Production Deployment

1. **Build and run with Docker Compose**
   ```bash
   docker-compose -f docker-compose.prod.yaml up -d
   ```

2. **Access the API**
   - Local: `http://localhost:8001`
   - Production: `http://<elastic-ip>:8001`

## ğŸ”Œ API Endpoints

### Health Check
```bash
GET /
```
Response:
```json
{
  "status": "healthy"
}
```

### Upload File
```bash
POST /upload
Content-Type: multipart/form-data
```
Example:
```bash
curl -X POST -F "file=@resume.pdf" http://localhost:8001/upload
```
Response:
```json
{
  "file_id": "507f1f77bcf86cd799439011"
}
```

### Get Processing Status
```bash
GET /{id}
```
Example:
```bash
curl http://localhost:8001/507f1f77bcf86cd799439011
```
Response:
```json
{
  "_id": "507f1f77bcf86cd799439011",
  "name": "resume.pdf",
  "status": "api call done",
  "result": "AI-generated analysis..."
}
```

## ğŸ­ Production Architecture

### AWS Deployment
- **EC2 Instance**: Hosts Docker containers
- **Elastic IP**: Static IP for consistent access
- **Load Balancer**: Distributes traffic across instances
- **Security Groups**: Port 8001 open for API access

### Scalability Considerations
- Multiple worker containers can be spawned for parallel processing
- Load balancer enables horizontal scaling
- Redis queue handles job distribution efficiently
- Stateless API design allows easy replication

## ğŸ“Š Processing Pipeline

```
Status Flow:
saving â†’ queued â†’ processing â†’ conversion complete â†’ api call done
```

## ğŸ” Environment Variables

```bash
OPENAI_API_KEY=sk-your-api-key-here
```

## ğŸ§ª Development

### Project Structure
```
full-rag/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ client.py          # MongoDB connection
â”‚   â”‚   â”œâ”€â”€ db.py              # Database instance
â”‚   â”‚   â””â”€â”€ collections/
â”‚   â”‚       â””â”€â”€ files.py       # Files collection schema
â”‚   â”œâ”€â”€ queue/
â”‚   â”‚   â”œâ”€â”€ q.py               # Redis Queue setup
â”‚   â”‚   â””â”€â”€ workers.py         # Background job processor
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ file.py            # File I/O utilities
â”‚   â”œâ”€â”€ main.py                # Application entry point
â”‚   â””â”€â”€ server.py              # FastAPI routes
â”œâ”€â”€ .devcontainer/             # Development container config
â”œâ”€â”€ docker-compose.prod.yaml   # Production orchestration
â”œâ”€â”€ Dockerfile                 # Production image
â””â”€â”€ requirements.txt           # Python dependencies
```

### Running Tests
```bash
# Start services
docker-compose -f .devcontainer/docker-compose.yaml up

# Run the server
./run.sh

# In another terminal, start worker
rq worker --with-scheduler --url redis://valkey:6379
```

## ğŸ“ Learning Outcomes

This project demonstrates understanding of:

1. **Async Programming**: Non-blocking I/O with async/await patterns
2. **Microservices Architecture**: Decoupled services communicating via message queues
3. **Job Queue Systems**: Background task processing with RQ
4. **Database Design**: NoSQL document storage with MongoDB
5. **API Design**: RESTful endpoints with FastAPI
6. **Containerization**: Docker multi-service orchestration
7. **Cloud Infrastructure**: AWS deployment with load balancing
8. **Security**: Environment variable management for secrets
9. **File Processing**: PDF manipulation and image encoding
10. **AI Integration**: OpenAI Vision API for document analysis

## ğŸš§ Future Improvements

- [ ] Add authentication/authorization
- [ ] Implement rate limiting
- [ ] Add comprehensive error handling
- [ ] Create unit and integration tests
- [ ] Set up CI/CD pipeline
- [ ] Add monitoring and logging (Prometheus, Grafana)
- [ ] Implement caching strategy
- [ ] Add webhook notifications for job completion
- [ ] Support multiple file types
- [ ] Add retry logic for failed jobs

## ğŸ“ License

This is a learning project created for educational purposes.

## ğŸ™ Acknowledgments

Built to understand and implement production-grade GenAI system design patterns used in real-world applications.

---

**Note**: This project is for learning purposes. The API key should be rotated and the hardcoded credentials in MongoDB should be replaced with secure secret management in production environments.
